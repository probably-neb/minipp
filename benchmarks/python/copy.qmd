---
title: "Compiles Final Paper"
date: today
format:
   html:
       code-fold: true
jupyter: python3
---
## Parsing
An aspect of our compiler that we are particularly proud of is our parser. For our compiler, we decided not to use ANTLR or any other parser generator. Instead, we wrote our own tokenizer and parser. This lets us have more control over the parsing of the program and allows us to make it faster as well.

### Tokenizer
The tokenizer breaks up the plain text input into a list of tokens which will be referenced by the parser. Each token has a "TokenKind" and "Range". The token kind is an enum that represents the type of the token, such as an identifier or number literal. Token kind also holds a simple mapping from keyword strings to their respective token kinds. The range is a simple struct that holds the start and end positions of the respective token in the input text. Range has a method to get the text of the token from the input text which is used when parsing the program.

### Parser
The parser constructs the ast from the list of tokens generated by the tokenizer/lexer. The Parser has the following feilds:
- `tokens` - The list of tokens generated by the tokenizer
- `input` - The input text
- `ast` - The abstract syntax tree
- `astLen` - The length of the ast (debugging purposes)
- `pos` - The current position in the list of tokens
- `readPos` - The next position in the list of tokens
- `allocator` - The standard Zig allocator for allocating memory

//// need to add more here

### PRATT Parsing
The parser uses a pratt parser to parse the program with correct operator precedence. This is important to keep the structure of the AST in a way that we can use pre-order traversal to generate the IR. The pratt parser uses recursive decent to parse the program in multiple passes. The first pass finds an expression and skips over ordering the expression while marking the start and the number of tokens that were skipped. The second pass then orders the expression based on the operator precedence. This allows us to construct the AST so a pre-order traversal reflects the order of operations in the program.

### AST
Each node in the AST consists of a "Kind" and a "Token". The "Token" refers to the token created earlier by the tokenizer. The "Kind" is another enum that represents the type of node in the AST. Each kind consists of a left and right child (both usize indexes into the AST). The lhs and rhs are then have specific varient names that are used for specific nodes in the AST. For example, the binary operators use just lhs and rhs, while a selector has a factor and a chain. 


## Static Semantics:

### Type Checking
Recursive descent is performed on the AST, with all functions returning the type or an error if invalid. The expression on the condition is checked to ensure it is a boolean before proceeding. If the expression is a selector, the corresponding struct is checked to ensure it contains the specified field.

### Return path checking
The return path is checked by traversing the AST and ensuring that all paths return a value. If a conditional is found, a return path must be found in both branches. If their is no return path in one of the branches then there must be a return path in the trailing code. We skip over while loops as the haulting problem is not solvable.

## Intermediate Representation

Our compiler stores the IR as a list of functions.
Each function then stores a list of all the registers,
instructions, and basic blocks. Each basic block stores and ordered list of references to instructions. Each instruction stores references to the registers it uses as well as the register it writes to and any other instruction specific data.

The IR is used as a control flow graph as well through the references which the basic blocks hold. This is esspecialy usefull for



## Optimizations:
For our compiler, we implemented the following optimizations:
### Sparse Conditional Constant Propagation
First, we implemented SCCP which propogates constant values. If while propogating a constant value, a conditional branch is reached, and the condition is known, we only continue propogating down that branch. Once we are finished any unreachable basic blocks are removed, and references to things in the blocks like phi nodes are replaced with the constant value.

### Comparison Propagation
On top of SCCP, we implemented comparison propagation. This is an extention of SCCP that evalueates comparisons and removes redundant ones. For example, if we check that a value is less than some number and then check again if it is biger than some larger number, we can remove the child comparison as it is impossible to be true. We also can create constants from direct comparisons. For example, if we compare a value to 0, we can do constant propogation on the value in the branch where it is the case where the value is 0.

### Dead Code Elimination
Finaly, we implemented mark and sweep dead code elimination. This was fairly straightforward to implement. For each function in the IR, we first marked all the side effects like calls as well as the return value. Then we marked everything that the marked values relied on. Finally we removed anything not marked.

### Empty Block Removal
Somewhat related to dead code elimination, we also implemented empty block removal which removes any basic blocks with only a single jump instruction.

## Code Generation and Register Allocation

The code generation uses a structure modeled around the ARMv8 specification for instructions to hold the data necessary for each instruction. This structure includes an operation, a destination register, and two operands. Since there are fundamentally no types when using GP registers, the typed IR representation of registers is converted into a type-agnostic form for the final output code. Each register and instruction is stored at the program level, with functions and basic blocks only holding references to the program’s master list. Each instruction is translated from the IR to the ARM representation in block order, in reverse post order of the basic blocks, and in function definition order.

All phi nodes are collected into a list and then removed because they do not exist in the computer’s representation of data, necessitating the implementation of the logic they represent at some point. Since SSA is no longer in use, the phi’s assigned register is placed in both of the incoming blocks. The compiler removes the phi nodes by creating a new unique register for the phi’s result. Every input is assigned to this unique register, and the phi’s register is assigned from this unique register, which is then pushed to all needed nodes. A fillback block is created on looping edges to hold this assignment, and finally, the phi register is renamed in all trailing live usages.


```{python}
import altair as alt
import pandas as pd
import json 
import os

# Create a simple dataframe from test.csv
data = json.load(open("times.json"))
dfs = {}
for key in data.keys():
   dfs[key] = pd.DataFrame(data[key])
lineCountData = json.load(open("instrCounts.json"))
istrCountDfs = {}
for key in lineCountData.keys():
   istrCountDfs[key] = pd.DataFrame(lineCountData[key])

```

```{python}
def plot(df_name):
   df = dfs[df_name]
   df_melted = df.melt(var_name="Compolation Type", value_name="Time (s)")
   chart = alt.Chart(df_melted).mark_boxplot(extent="min-max").encode(
      alt.X('Time (s):Q', title='Time (s)', scale=alt.Scale(nice = True, zero=False)),
      alt.Y('Compolation Type:O', title='Compolation Type'),
      alt.Color('Compolation Type:O', title=None, legend=None,  # Disable the legend
         scale=alt.Scale(scheme='category10'))
   ).properties(
      width=600,  # Adjust the width
      height=200  # Adjust the height
      )

   summary_stats = df_melted.groupby('Compolation Type')['Time (s)'].agg(['mean', 'std', 'count']).reset_index()
   summary_stats.columns = ['Compolation Type', 'Average Time (s)', 'Standard Deviation (s)', 'Number of Runs']

   table = alt.Chart(summary_stats).transform_fold(
       fold=['Average Time (s)', 'Standard Deviation (s)', 'Number of Runs'],
       as_=['Statistic', 'Value']
   ).mark_text().encode(
       alt.Y('Compolation Type:O', title='Compolation Type'),
       alt.X('Statistic:N', title='Statistic'),
       alt.Text('Value:Q', format=".4e"),
       alt.Color('Statistic:N', legend=None)  # Use color for text differentiation
   ).properties(
       width=600,  # Match the width of the chart
       height=100  # Adjust the height of the table
   )

   instrDf = istrCountDfs[df_name].melt(var_name="Compolation Type", value_name="Instructions")

   istrCountPlot = alt.Chart(instrDf).mark_bar().encode(
      alt.X('Instructions:Q', title='Instructions', scale=alt.Scale(nice = True, zero=False)),
      alt.Y('Compolation Type:O', title='Compolation Type'),
      alt.Color('Compolation Type:O', title=None, legend=None,  # Disable the legend
         scale=alt.Scale(scheme='category10'))
   ).properties(
      width=600,  # Adjust the width
      height=200  # Adjust the height
      )

   combined = alt.vconcat(
        chart,
        table,
        istrCountPlot
   ).resolve_scale(
           color='independent'
           )
   return combined
```

### BenchMarkishTopics
```{python}
plot("BenchMarkishTopics")
```
### Fibonacci
```{python}
plot("Fibonacci")
```
### GeneralFunctAndOptimize
```{python}
plot("GeneralFunctAndOptimize")
```
### OptimizationBenchmark
```{python}
plot("OptimizationBenchmark")
```
### TicTac
```{python}
plot("TicTac")
```
### array_sort
```{python}
plot("array_sort")
```
### array_sum
```{python}
plot("array_sum")
```
### bert
```{python}
plot("bert")
```
### biggest
```{python}
plot("biggest")
```
### binaryConverter
```{python}
plot("binaryConverter")
```
### brett
```{python}
plot("brett")
```
### creativeBenchMarkName
```{python}
plot("creativeBenchMarkName")
```
### fact_sum
```{python}
plot("fact_sum")
```
### hailstone
```{python}
plot("hailstone")
```
### hanoi_benchmark
```{python}
plot("hanoi_benchmark")
```
### killerBubbles
```{python}
plot("killerBubbles")
```
### mile1
```{python}
plot("mile1")
```
### mixed
```{python}
plot("mixed")
```
### primes
```{python}
plot("primes")
```
### programBreaker
```{python}
plot("programBreaker")
```
### stats
```{python}
plot("stats")
```
### wasteOfCycles
```{python}
plot("wasteOfCycles")
```
