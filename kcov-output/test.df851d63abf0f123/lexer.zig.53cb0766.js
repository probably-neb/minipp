var data = {lines:[
{"lineNum":"    1","line":"const std = @import(\"std\");"},
{"lineNum":"    2","line":"const log = @import(\"log.zig\");"},
{"lineNum":"    3","line":""},
{"lineNum":"    4","line":"/// Print function that only prints in test mode. Useful for printing info"},
{"lineNum":"    5","line":"/// for debugging purposes that you don\'t want to show up when not running tests"},
{"lineNum":"    6","line":"fn test_print(comptime fmt: []const u8, args: anytype) void {"},
{"lineNum":"    7","line":"    const builtin = @import(\"builtin\");"},
{"lineNum":"    8","line":"    if (builtin.is_test) {"},
{"lineNum":"    9","line":"        log.err(fmt, args);"},
{"lineNum":"   10","line":"    }"},
{"lineNum":"   11","line":"}"},
{"lineNum":"   12","line":""},
{"lineNum":"   13","line":"pub const Range = struct {"},
{"lineNum":"   14","line":"    start: u32,"},
{"lineNum":"   15","line":"    end: u32,"},
{"lineNum":"   16","line":""},
{"lineNum":"   17","line":"    pub fn new(start: u32, end: u32) Range {","class":"lineCov","hits":"1","order":"848","possible_hits":"1",},
{"lineNum":"   18","line":"        return Range{ .start = start, .end = end };","class":"lineCov","hits":"1","order":"849","possible_hits":"1",},
{"lineNum":"   19","line":"    }"},
{"lineNum":"   20","line":""},
{"lineNum":"   21","line":"    pub fn getSubStrFromStr(self: Range, str: []const u8) []const u8 {","class":"lineCov","hits":"1","order":"916","possible_hits":"1",},
{"lineNum":"   22","line":"        return str[self.start..self.end];","class":"lineCov","hits":"1","order":"917","possible_hits":"1",},
{"lineNum":"   23","line":"    }"},
{"lineNum":"   24","line":""},
{"lineNum":"   25","line":"    pub fn getLineCont(self: Range, input: []const u8) []const u8 {","class":"lineCov","hits":"1","order":"3260","possible_hits":"1",},
{"lineNum":"   26","line":"        var start = self.start;","class":"lineCov","hits":"1","order":"3261","possible_hits":"1",},
{"lineNum":"   27","line":"        if (start == input.len) {","class":"lineCov","hits":"1","order":"3262","possible_hits":"1",},
{"lineNum":"   28","line":"            start -= 1;","class":"lineCov","hits":"1","order":"3263","possible_hits":"1",},
{"lineNum":"   29","line":"        }"},
{"lineNum":"   30","line":"        while (start > 0 and start < input.len and input[start] != \'\\n\') {","class":"lineCov","hits":"2","order":"3264","possible_hits":"2",},
{"lineNum":"   31","line":"            start -= 1;","class":"lineCov","hits":"2","order":"3265","possible_hits":"2",},
{"lineNum":"   32","line":"        }"},
{"lineNum":"   33","line":"        var end = self.end;","class":"lineCov","hits":"1","order":"3266","possible_hits":"1",},
{"lineNum":"   34","line":"        while (end < input.len and input[end] != \'\\n\' and end >= 0) {","class":"lineCov","hits":"2","order":"3267","possible_hits":"2",},
{"lineNum":"   35","line":"            end += 1;","class":"lineCov","hits":"2","order":"3268","possible_hits":"2",},
{"lineNum":"   36","line":"        }"},
{"lineNum":"   37","line":"        return input[start..end];","class":"lineCov","hits":"2","order":"3269","possible_hits":"2",},
{"lineNum":"   38","line":"    }"},
{"lineNum":"   39","line":""},
{"lineNum":"   40","line":"    pub fn printLineContUnderline(self: Range, input: []const u8) void {","class":"lineCov","hits":"1","order":"3271","possible_hits":"1",},
{"lineNum":"   41","line":"        var start = self.start;","class":"lineCov","hits":"1","order":"3272","possible_hits":"1",},
{"lineNum":"   42","line":"        if (start == input.len) {","class":"lineCov","hits":"1","order":"3273","possible_hits":"1",},
{"lineNum":"   43","line":"            start -= 1;","class":"lineCov","hits":"1","order":"3274","possible_hits":"1",},
{"lineNum":"   44","line":"        }"},
{"lineNum":"   45","line":"        while (start > 0 and start < input.len and input[start] != \'\\n\') {","class":"lineCov","hits":"2","order":"3275","possible_hits":"2",},
{"lineNum":"   46","line":"            start -= 1;","class":"lineCov","hits":"2","order":"3276","possible_hits":"2",},
{"lineNum":"   47","line":"        }"},
{"lineNum":"   48","line":"        var end = self.end;","class":"lineCov","hits":"1","order":"3277","possible_hits":"1",},
{"lineNum":"   49","line":"        while (end < input.len and end >= 0 and input[end] != \'\\n\') {","class":"lineCov","hits":"2","order":"3278","possible_hits":"2",},
{"lineNum":"   50","line":"            end += 1;","class":"lineCov","hits":"3","order":"3279","possible_hits":"3",},
{"lineNum":"   51","line":"        }"},
{"lineNum":"   52","line":""},
{"lineNum":"   53","line":"        // print spaces from start to self.start"},
{"lineNum":"   54","line":"        // // print ^ from self.start to self.end"},
{"lineNum":"   55","line":"        // // print spaces from self.end to end"},
{"lineNum":"   56","line":"        while (start < self.start) {","class":"lineCov","hits":"1","order":"3280","possible_hits":"1",},
{"lineNum":"   57","line":"            log.err(\" \", .{});","class":"lineCov","hits":"1","order":"3281","possible_hits":"1",},
{"lineNum":"   58","line":"            start += 1;","class":"lineCov","hits":"2","order":"3282","possible_hits":"2",},
{"lineNum":"   59","line":"        }"},
{"lineNum":"   60","line":"        if (self.start == self.end) {","class":"lineCov","hits":"1","order":"3283","possible_hits":"1",},
{"lineNum":"   61","line":"            log.err(\"^\", .{});","class":"lineCov","hits":"1","order":"3284","possible_hits":"1",},
{"lineNum":"   62","line":"            start += 1;","class":"lineCov","hits":"2","order":"3285","possible_hits":"2",},
{"lineNum":"   63","line":"        }"},
{"lineNum":"   64","line":"        while (start < self.end) {","class":"lineCov","hits":"1","order":"3286","possible_hits":"1",},
{"lineNum":"   65","line":"            log.err(\"^\", .{});","class":"lineCov","hits":"1","order":"3314","possible_hits":"1",},
{"lineNum":"   66","line":"            start += 1;","class":"lineCov","hits":"3","order":"3287","possible_hits":"3",},
{"lineNum":"   67","line":"        }"},
{"lineNum":"   68","line":"        while (start < end) {","class":"lineCov","hits":"1","order":"3288","possible_hits":"1",},
{"lineNum":"   69","line":"            log.err(\" \", .{});","class":"lineCov","hits":"1","order":"3289","possible_hits":"1",},
{"lineNum":"   70","line":"            start += 1;","class":"lineCov","hits":"2","order":"3290","possible_hits":"2",},
{"lineNum":"   71","line":"        }"},
{"lineNum":"   72","line":"        log.err(\"\\n\", .{});","class":"lineCov","hits":"1","order":"3291","possible_hits":"1",},
{"lineNum":"   73","line":"    }"},
{"lineNum":"   74","line":"};"},
{"lineNum":"   75","line":""},
{"lineNum":"   76","line":"// TODO: include range in Token struct and have getter function for it"},
{"lineNum":"   77","line":"// so we don\'t have to track/compute it for trivially known values (like keywords or `==`)"},
{"lineNum":"   78","line":"pub const TokenKind = enum {"},
{"lineNum":"   79","line":"    // For error handling and reporting"},
{"lineNum":"   80","line":"    Identifier,"},
{"lineNum":"   81","line":"    Number,"},
{"lineNum":"   82","line":"    Lt,"},
{"lineNum":"   83","line":"    LtEq,"},
{"lineNum":"   84","line":"    Gt,"},
{"lineNum":"   85","line":"    GtEq,"},
{"lineNum":"   86","line":"    Eq,"},
{"lineNum":"   87","line":"    Dot,"},
{"lineNum":"   88","line":"    DoubleEq,"},
{"lineNum":"   89","line":"    NotEq,"},
{"lineNum":"   90","line":"    Not,"},
{"lineNum":"   91","line":"    Plus,"},
{"lineNum":"   92","line":"    Minus,"},
{"lineNum":"   93","line":"    Mul,"},
{"lineNum":"   94","line":"    Div,"},
{"lineNum":"   95","line":"    LParen,"},
{"lineNum":"   96","line":"    RParen,"},
{"lineNum":"   97","line":"    LCurly,"},
{"lineNum":"   98","line":"    RCurly,"},
{"lineNum":"   99","line":"    Semicolon,"},
{"lineNum":"  100","line":"    Eof,"},
{"lineNum":"  101","line":"    Or,"},
{"lineNum":"  102","line":"    And,"},
{"lineNum":"  103","line":"    Comma,"},
{"lineNum":"  104","line":"    KeywordBool,"},
{"lineNum":"  105","line":"    KeywordDelete,"},
{"lineNum":"  106","line":"    KeywordElse,"},
{"lineNum":"  107","line":"    KeywordEndl,"},
{"lineNum":"  108","line":"    KeywordFalse,"},
{"lineNum":"  109","line":"    KeywordFun,"},
{"lineNum":"  110","line":"    KeywordIf,"},
{"lineNum":"  111","line":"    KeywordInt,"},
{"lineNum":"  112","line":"    KeywordNew,"},
{"lineNum":"  113","line":"    KeywordNull,"},
{"lineNum":"  114","line":"    KeywordPrint,"},
{"lineNum":"  115","line":"    KeywordRead,"},
{"lineNum":"  116","line":"    KeywordReturn,"},
{"lineNum":"  117","line":"    KeywordStruct,"},
{"lineNum":"  118","line":"    KeywordTrue,"},
{"lineNum":"  119","line":"    KeywordVoid,"},
{"lineNum":"  120","line":"    KeywordWhile,"},
{"lineNum":"  121","line":"    Unset,"},
{"lineNum":"  122","line":""},
{"lineNum":"  123","line":"    // NOTE: bool, int, void shouldn\'t be valid keywords, (valid /type/ names)"},
{"lineNum":"  124","line":"    // and I feel that anything returned from the keywords map should be a keyword"},
{"lineNum":"  125","line":"    // we should move checking for \"int\"/\"bool\"/\"void\" to the type checking/name resolution steps (type name resolution)"},
{"lineNum":"  126","line":"    // when it exists"},
{"lineNum":"  127","line":"    pub const keywords = std.ComptimeStringMap(TokenKind, .{"},
{"lineNum":"  128","line":"        .{ \"bool\", TokenKind.KeywordBool },"},
{"lineNum":"  129","line":"        .{ \"delete\", TokenKind.KeywordDelete },"},
{"lineNum":"  130","line":"        .{ \"else\", TokenKind.KeywordElse },"},
{"lineNum":"  131","line":"        .{ \"endl\", TokenKind.KeywordEndl },"},
{"lineNum":"  132","line":"        .{ \"false\", TokenKind.KeywordFalse },"},
{"lineNum":"  133","line":"        .{ \"fun\", TokenKind.KeywordFun },"},
{"lineNum":"  134","line":"        .{ \"if\", TokenKind.KeywordIf },"},
{"lineNum":"  135","line":"        .{ \"int\", TokenKind.KeywordInt },"},
{"lineNum":"  136","line":"        .{ \"new\", TokenKind.KeywordNew },"},
{"lineNum":"  137","line":"        .{ \"null\", TokenKind.KeywordNull },"},
{"lineNum":"  138","line":"        .{ \"print\", TokenKind.KeywordPrint },"},
{"lineNum":"  139","line":"        .{ \"read\", TokenKind.KeywordRead },"},
{"lineNum":"  140","line":"        .{ \"return\", TokenKind.KeywordReturn },"},
{"lineNum":"  141","line":"        .{ \"struct\", TokenKind.KeywordStruct },"},
{"lineNum":"  142","line":"        .{ \"true\", TokenKind.KeywordTrue },"},
{"lineNum":"  143","line":"        .{ \"void\", TokenKind.KeywordVoid },"},
{"lineNum":"  144","line":"        .{ \"while\", TokenKind.KeywordWhile },"},
{"lineNum":"  145","line":"    });"},
{"lineNum":"  146","line":""},
{"lineNum":"  147","line":"    pub fn equals(self: TokenKind, other: TokenKind) bool {","class":"lineCov","hits":"1","order":"900","possible_hits":"1",},
{"lineNum":"  148","line":"        const self_tag = @intFromEnum(self);","class":"lineCov","hits":"1","order":"901","possible_hits":"1",},
{"lineNum":"  149","line":"        const other_tag = @intFromEnum(other);","class":"lineCov","hits":"1","order":"902","possible_hits":"1",},
{"lineNum":"  150","line":""},
{"lineNum":"  151","line":"        return self_tag == other_tag;","class":"lineCov","hits":"1","order":"903","possible_hits":"1",},
{"lineNum":"  152","line":"    }"},
{"lineNum":"  153","line":"};"},
{"lineNum":"  154","line":""},
{"lineNum":"  155","line":"// TODO: remove unecessary fields"},
{"lineNum":"  156","line":"// line (Range), column, line_no are only needed for errors and debug sybmols"},
{"lineNum":"  157","line":"// and encode the same information. Could realistcally be replaced with a single `start_index`"},
{"lineNum":"  158","line":"// and we can just reparse later. UX for that api / speed tradeoff TBD"},
{"lineNum":"  159","line":"pub const Token = struct {"},
{"lineNum":"  160","line":"    kind: TokenKind,"},
{"lineNum":"  161","line":"    // TODO: create getter method for range that compute it for trivial cases"},
{"lineNum":"  162","line":"    // and returns precomputed value if present."},
{"lineNum":"  163","line":"    // NOTE - must assert that the range is valid in non-trivial cases (Number/Identifier)"},
{"lineNum":"  164","line":"    // ALSO NOTE - It\'s not that much work to compute it for everythnig"},
{"lineNum":"  165","line":"    // and takes up the same amount of memory"},
{"lineNum":"  166","line":"    _range: Range,"},
{"lineNum":"  167","line":"};"},
{"lineNum":"  168","line":""},
{"lineNum":"  169","line":"// FIXME: handle comments"},
{"lineNum":"  170","line":"pub const Lexer = struct {"},
{"lineNum":"  171","line":"    // For error handling and reporting"},
{"lineNum":"  172","line":"    line_number: u32,"},
{"lineNum":"  173","line":"    column: u32,"},
{"lineNum":"  174","line":"    file: []const u8,"},
{"lineNum":"  175","line":"    line: Range,"},
{"lineNum":"  176","line":""},
{"lineNum":"  177","line":"    // The current position in the input"},
{"lineNum":"  178","line":"    pos: u32,"},
{"lineNum":"  179","line":"    // The position that we are currently reading"},
{"lineNum":"  180","line":"    read_pos: u32,"},
{"lineNum":"  181","line":"    // The current character we are reading"},
{"lineNum":"  182","line":"    ch: u8,"},
{"lineNum":"  183","line":"    // The input string"},
{"lineNum":"  184","line":"    input: []const u8,"},
{"lineNum":"  185","line":""},
{"lineNum":"  186","line":"    /// Internal struct for holding info required to construct a full token"},
{"lineNum":"  187","line":"    /// Used as a DTO (data transfer object)"},
{"lineNum":"  188","line":"    /// A good example is the `ident_or_builtin` function which returns"},
{"lineNum":"  189","line":"    /// the keyword token type and a null range if it was a keyword"},
{"lineNum":"  190","line":"    /// (because range of keyword is trivially known based on start + len)"},
{"lineNum":"  191","line":"    /// or the `Identifier` token type and the range if it was an ident"},
{"lineNum":"  192","line":"    const TokInfo = struct {"},
{"lineNum":"  193","line":"        kind: TokenKind,"},
{"lineNum":"  194","line":"        range: Range,"},
{"lineNum":"  195","line":"    };"},
{"lineNum":"  196","line":""},
{"lineNum":"  197","line":"    pub fn new(input: []const u8, filePath: []const u8) Lexer {","class":"lineCov","hits":"1","order":"707","possible_hits":"1",},
{"lineNum":"  198","line":"        var lxr = Lexer{","class":"lineCov","hits":"1","order":"708","possible_hits":"1",},
{"lineNum":"  199","line":"            .line_number = 0,"},
{"lineNum":"  200","line":"            .column = 0,"},
{"lineNum":"  201","line":"            .file = filePath,"},
{"lineNum":"  202","line":"            .line = Range{ .start = 0, .end = 0 },"},
{"lineNum":"  203","line":"            .pos = 0,"},
{"lineNum":"  204","line":"            .read_pos = 0,"},
{"lineNum":"  205","line":"            .ch = 0,"},
{"lineNum":"  206","line":"            .input = input,"},
{"lineNum":"  207","line":"        };"},
{"lineNum":"  208","line":"        lxr.step();","class":"lineCov","hits":"1","order":"709","possible_hits":"1",},
{"lineNum":"  209","line":"        return lxr;","class":"lineCov","hits":"1","order":"715","possible_hits":"1",},
{"lineNum":"  210","line":"    }"},
{"lineNum":"  211","line":""},
{"lineNum":"  212","line":"    pub fn newFromStr(input: []const u8) Lexer {"},
{"lineNum":"  213","line":"        return Lexer.new(input, \"\");"},
{"lineNum":"  214","line":"    }"},
{"lineNum":"  215","line":""},
{"lineNum":"  216","line":"    /// Tokenizes the input string and returns a list of tokens."},
{"lineNum":"  217","line":"    /// It returns an owned slice of tokens."},
{"lineNum":"  218","line":"    /// @param input:[]const u8 - The input string to tokenize"},
{"lineNum":"  219","line":"    /// @param filePath:[]const u8 - The file path of the input string"},
{"lineNum":"  220","line":"    /// @param allocator:std.mem.Allocator - The allocator to use for allocating memory"},
{"lineNum":"  221","line":"    /// @return []Token - The list of tokens"},
{"lineNum":"  222","line":"    /// NOTE: if you are using a string use the functinon tokenizeFromStr instead"},
{"lineNum":"  223","line":"    pub fn tokenize(input: []const u8, filePath: []const u8, allocator: std.mem.Allocator) ![]Token {","class":"lineCov","hits":"1","order":"705","possible_hits":"1",},
{"lineNum":"  224","line":"        var lexer = Lexer.new(input, filePath);","class":"lineCov","hits":"1","order":"706","possible_hits":"1",},
{"lineNum":"  225","line":"        var tokens = std.ArrayList(Token).init(allocator);","class":"lineCov","hits":"1","order":"716","possible_hits":"1",},
{"lineNum":"  226","line":"        defer tokens.deinit();","class":"linePartCov","hits":"2","order":"820","possible_hits":"3",},
{"lineNum":"  227","line":""},
{"lineNum":"  228","line":"        // NOTE: EOF is the always token, it makes part of parsing simpler, so I will revise tests to match"},
{"lineNum":"  229","line":"        while (true) {"},
{"lineNum":"  230","line":"            const tok = try lexer.next_token();","class":"lineCov","hits":"2","order":"717","possible_hits":"2",},
{"lineNum":"  231","line":"            try tokens.append(tok);","class":"linePartCov","hits":"1","order":"751","possible_hits":"2",},
{"lineNum":"  232","line":"            if (tok.kind == TokenKind.Eof) {","class":"lineCov","hits":"1","order":"777","possible_hits":"1",},
{"lineNum":"  233","line":"                break;","class":"lineCov","hits":"1","order":"778","possible_hits":"1",},
{"lineNum":"  234","line":"            }"},
{"lineNum":"  235","line":"        }"},
{"lineNum":"  236","line":""},
{"lineNum":"  237","line":"        return tokens.toOwnedSlice();","class":"lineCov","hits":"3","order":"812","possible_hits":"3",},
{"lineNum":"  238","line":"    }"},
{"lineNum":"  239","line":""},
{"lineNum":"  240","line":"    /// Tokenizes the input string and returns a list of tokens."},
{"lineNum":"  241","line":"    /// This is an alias for lexer.tokenize, using a file path of \"\"."},
{"lineNum":"  242","line":"    /// @param input:[]const u8 - The input string to tokenize"},
{"lineNum":"  243","line":"    /// @param allocator:std.mem.Allocator - The allocator to use for allocating memory"},
{"lineNum":"  244","line":"    /// @return []Token - The list of tokens"},
{"lineNum":"  245","line":"    pub fn tokenizeFromStr(input: []const u8, allocator: std.mem.Allocator) ![]Token {","class":"lineCov","hits":"1","order":"703","possible_hits":"1",},
{"lineNum":"  246","line":"        return Lexer.tokenize(input, \"\", allocator);","class":"lineCov","hits":"1","order":"704","possible_hits":"1",},
{"lineNum":"  247","line":"    }"},
{"lineNum":"  248","line":""},
{"lineNum":"  249","line":"    pub fn next_token(lxr: *Lexer) !Token {","class":"lineCov","hits":"1","order":"718","possible_hits":"1",},
{"lineNum":"  250","line":"        lxr.skip_whitespace();","class":"lineCov","hits":"1","order":"719","possible_hits":"1",},
{"lineNum":"  251","line":""},
{"lineNum":"  252","line":"        const info: TokInfo = switch (lxr.ch) {","class":"lineCov","hits":"2","order":"724","possible_hits":"2",},
{"lineNum":"  253","line":"            \'a\'...\'z\', \'A\'...\'Z\' => lxr.ident_or_builtin(),","class":"lineCov","hits":"1","order":"725","possible_hits":"1",},
{"lineNum":"  254","line":"            \'0\'...\'9\' => .{ .kind = TokenKind.Number, .range = try lxr.read_number() },","class":"lineCov","hits":"1","order":"1316","possible_hits":"1",},
{"lineNum":"  255","line":"            else => blk: {"},
{"lineNum":"  256","line":"                const pos = lxr.pos;","class":"lineCov","hits":"1","order":"784","possible_hits":"1",},
{"lineNum":"  257","line":"                if (std.ascii.isPrint(lxr.ch)) {","class":"lineCov","hits":"1","order":"785","possible_hits":"1",},
{"lineNum":"  258","line":"                    break :blk .{ .kind = try lxr.read_symbol(), .range = Range{ .start = pos, .end = pos } };","class":"lineCov","hits":"1","order":"792","possible_hits":"1",},
{"lineNum":"  259","line":"                }"},
{"lineNum":"  260","line":"                if (lxr.ch == 0) {","class":"lineCov","hits":"1","order":"810","possible_hits":"1",},
{"lineNum":"  261","line":"                    // TODO: return null and make return type ?Token"},
{"lineNum":"  262","line":"                    // so that we can use `while (lxr.next_token()) |tok|`"},
{"lineNum":"  263","line":"                    // pattern"},
{"lineNum":"  264","line":"                    break :blk .{ .kind = TokenKind.Eof, .range = Range{ .start = pos, .end = pos } };","class":"lineCov","hits":"1","order":"811","possible_hits":"1",},
{"lineNum":"  265","line":"                }"},
{"lineNum":"  266","line":"                // TODO: improve error handling"},
{"lineNum":"  267","line":"                if (lxr.file.len == 0) {","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  268","line":"                    log.err(\"unexpected character {any} in line=\\\"{s}\\\"@{any}:{any}\\n\", .{ lxr.ch, lxr.line.getSubStrFromStr(lxr.input), lxr.line_number, lxr.column });","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  269","line":"                } else {"},
{"lineNum":"  270","line":"                    log.err(\"error: unexpected character {any} in line=\\\"{s}\\\" in file=\\\"{s}\\\"@{any}:{any}\\n\", .{ lxr.ch, lxr.line.getSubStrFromStr(lxr.input), lxr.file, lxr.line_number, lxr.column });","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  271","line":"                }"},
{"lineNum":"  272","line":"                lxr.line.end = if (lxr.line.end == 0) @truncate(lxr.input.len) else lxr.line.end;","class":"lineNoCov","hits":"0","possible_hits":"2",},
{"lineNum":"  273","line":"                return error.InvalidToken;","class":"linePartCov","hits":"1","order":"798","possible_hits":"2",},
{"lineNum":"  274","line":"            },"},
{"lineNum":"  275","line":"        };"},
{"lineNum":"  276","line":""},
{"lineNum":"  277","line":"        const tok = Token{ .kind = info.kind, ._range = info.range };","class":"lineCov","hits":"1","order":"749","possible_hits":"1",},
{"lineNum":"  278","line":"        return tok;","class":"lineCov","hits":"1","order":"750","possible_hits":"1",},
{"lineNum":"  279","line":"    }"},
{"lineNum":"  280","line":""},
{"lineNum":"  281","line":"    fn step(lxr: *Lexer) void {","class":"lineCov","hits":"1","order":"710","possible_hits":"1",},
{"lineNum":"  282","line":"        if (lxr.read_pos >= lxr.input.len) {","class":"lineCov","hits":"1","order":"711","possible_hits":"1",},
{"lineNum":"  283","line":"            lxr.ch = 0;","class":"lineCov","hits":"1","order":"799","possible_hits":"1",},
{"lineNum":"  284","line":"        } else {"},
{"lineNum":"  285","line":"            lxr.ch = lxr.input[lxr.read_pos];","class":"lineCov","hits":"1","order":"712","possible_hits":"1",},
{"lineNum":"  286","line":"        }"},
{"lineNum":"  287","line":""},
{"lineNum":"  288","line":"        lxr.pos = lxr.read_pos;","class":"lineCov","hits":"1","order":"713","possible_hits":"1",},
{"lineNum":"  289","line":"        lxr.read_pos += 1;","class":"linePartCov","hits":"1","order":"714","possible_hits":"2",},
{"lineNum":"  290","line":"    }"},
{"lineNum":"  291","line":""},
{"lineNum":"  292","line":"    fn step_if_next_is(lxr: *Lexer, ch: u8) bool {","class":"lineCov","hits":"1","order":"2054","possible_hits":"1",},
{"lineNum":"  293","line":"        if (lxr.peek() == ch) {","class":"lineCov","hits":"1","order":"2055","possible_hits":"1",},
{"lineNum":"  294","line":"            lxr.step();","class":"lineCov","hits":"1","order":"2471","possible_hits":"1",},
{"lineNum":"  295","line":"            return true;","class":"lineCov","hits":"1","order":"2472","possible_hits":"1",},
{"lineNum":"  296","line":"        }"},
{"lineNum":"  297","line":"        return false;","class":"lineCov","hits":"1","order":"2059","possible_hits":"1",},
{"lineNum":"  298","line":"    }"},
{"lineNum":"  299","line":""},
{"lineNum":"  300","line":"    fn peek(lxr: *Lexer) u8 {","class":"lineCov","hits":"1","order":"2056","possible_hits":"1",},
{"lineNum":"  301","line":"        if (lxr.read_pos >= lxr.input.len) {","class":"lineCov","hits":"1","order":"2057","possible_hits":"1",},
{"lineNum":"  302","line":"            return 0;","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  303","line":"        } else {"},
{"lineNum":"  304","line":"            return lxr.input[lxr.read_pos];","class":"lineCov","hits":"1","order":"2058","possible_hits":"1",},
{"lineNum":"  305","line":"        }"},
{"lineNum":"  306","line":"    }"},
{"lineNum":"  307","line":""},
{"lineNum":"  308","line":"    fn skip_whitespace(lxr: *Lexer) void {","class":"lineCov","hits":"1","order":"720","possible_hits":"1",},
{"lineNum":"  309","line":"        while (true) {"},
{"lineNum":"  310","line":"            switch (lxr.ch) {","class":"lineCov","hits":"1","order":"721","possible_hits":"1",},
{"lineNum":"  311","line":"                \'\\n\' => {"},
{"lineNum":"  312","line":"                    lxr.line_number += 1;","class":"lineCov","hits":"1","order":"2596","possible_hits":"1",},
{"lineNum":"  313","line":"                    lxr.column = 0;","class":"lineCov","hits":"1","order":"2597","possible_hits":"1",},
{"lineNum":"  314","line":"                    lxr.line.start = if (lxr.line.end == 0) 0 else lxr.line.end + 1;","class":"lineCov","hits":"2","order":"2598","possible_hits":"2",},
{"lineNum":"  315","line":"                    lxr.line.end = lxr.pos;","class":"lineCov","hits":"1","order":"2599","possible_hits":"1",},
{"lineNum":"  316","line":"                },"},
{"lineNum":"  317","line":"                \' \', \'\\t\', \'\\r\' => {"},
{"lineNum":"  318","line":"                    lxr.column += 1;","class":"lineCov","hits":"2","order":"722","possible_hits":"2",},
{"lineNum":"  319","line":"                },"},
{"lineNum":"  320","line":"                else => break,"},
{"lineNum":"  321","line":"            }"},
{"lineNum":"  322","line":"            lxr.step();","class":"lineCov","hits":"2","order":"723","possible_hits":"2",},
{"lineNum":"  323","line":"        }"},
{"lineNum":"  324","line":"    }"},
{"lineNum":"  325","line":""},
{"lineNum":"  326","line":"    fn read_ident(lxr: *Lexer) Range {","class":"lineCov","hits":"1","order":"728","possible_hits":"1",},
{"lineNum":"  327","line":"        const pos = lxr.pos;","class":"lineCov","hits":"1","order":"729","possible_hits":"1",},
{"lineNum":"  328","line":"        // NOTE: no need to check first char is not numeric here"},
{"lineNum":"  329","line":"        // because if first char was numeric we would have called"},
{"lineNum":"  330","line":"        // read_number instead"},
{"lineNum":"  331","line":"        while (std.ascii.isAlphanumeric(lxr.ch)) {","class":"lineCov","hits":"1","order":"730","possible_hits":"1",},
{"lineNum":"  332","line":"            lxr.step();","class":"lineCov","hits":"1","order":"733","possible_hits":"1",},
{"lineNum":"  333","line":"        }"},
{"lineNum":"  334","line":"        return Range{ .start = pos, .end = lxr.pos };","class":"lineCov","hits":"1","order":"734","possible_hits":"1",},
{"lineNum":"  335","line":"    }"},
{"lineNum":"  336","line":""},
{"lineNum":"  337","line":"    fn ident_or_builtin(lxr: *Lexer) TokInfo {","class":"lineCov","hits":"1","order":"726","possible_hits":"1",},
{"lineNum":"  338","line":"        const range = lxr.read_ident();","class":"lineCov","hits":"1","order":"727","possible_hits":"1",},
{"lineNum":"  339","line":"        const ident = lxr.slice(range);","class":"lineCov","hits":"1","order":"735","possible_hits":"1",},
{"lineNum":"  340","line":"        const kw = TokenKind.keywords.get(ident);","class":"lineCov","hits":"1","order":"739","possible_hits":"1",},
{"lineNum":"  341","line":"        if (kw) |kw_kind| {","class":"lineCov","hits":"2","order":"747","possible_hits":"2",},
{"lineNum":"  342","line":"            return .{ .kind = kw_kind, .range = range };","class":"lineCov","hits":"1","order":"748","possible_hits":"1",},
{"lineNum":"  343","line":"        }"},
{"lineNum":"  344","line":"        return .{ .kind = .Identifier, .range = range };","class":"lineCov","hits":"1","order":"783","possible_hits":"1",},
{"lineNum":"  345","line":"    }"},
{"lineNum":"  346","line":""},
{"lineNum":"  347","line":"    fn read_number(lxr: *Lexer) !Range {","class":"lineCov","hits":"1","order":"1317","possible_hits":"1",},
{"lineNum":"  348","line":"        const pos = lxr.pos;","class":"lineCov","hits":"1","order":"1318","possible_hits":"1",},
{"lineNum":"  349","line":"        while (std.ascii.isDigit(lxr.ch)) {","class":"lineCov","hits":"1","order":"1319","possible_hits":"1",},
{"lineNum":"  350","line":"            lxr.step();","class":"lineCov","hits":"1","order":"1322","possible_hits":"1",},
{"lineNum":"  351","line":"        }"},
{"lineNum":"  352","line":"        return Range{ .start = pos, .end = lxr.pos };","class":"lineCov","hits":"2","order":"1323","possible_hits":"2",},
{"lineNum":"  353","line":"    }"},
{"lineNum":"  354","line":""},
{"lineNum":"  355","line":"    fn read_symbol(lxr: *Lexer) !TokenKind {","class":"lineCov","hits":"1","order":"793","possible_hits":"1",},
{"lineNum":"  356","line":"        const tok: TokenKind = switch (lxr.ch) {","class":"lineCov","hits":"1","order":"794","possible_hits":"1",},
{"lineNum":"  357","line":"            \'<\' => if (lxr.step_if_next_is(\'=\')) .LtEq else .Lt,","class":"lineCov","hits":"1","order":"2600","possible_hits":"1",},
{"lineNum":"  358","line":"            \'>\' => if (lxr.step_if_next_is(\'=\')) .GtEq else .Gt,","class":"lineCov","hits":"1","order":"2469","possible_hits":"1",},
{"lineNum":"  359","line":"            \'=\' => if (lxr.step_if_next_is(\'=\')) .DoubleEq else .Eq,","class":"lineCov","hits":"1","order":"2053","possible_hits":"1",},
{"lineNum":"  360","line":"            \'!\' => if (lxr.step_if_next_is(\'=\')) .NotEq else .Not,","class":"lineCov","hits":"1","order":"2503","possible_hits":"1",},
{"lineNum":"  361","line":"            \'&\' => if (lxr.step_if_next_is(\'&\')) .And else return error.InvalidToken,","class":"lineCov","hits":"1","order":"2470","possible_hits":"1",},
{"lineNum":"  362","line":"            \'|\' => if (lxr.step_if_next_is(\'|\')) .Or else return error.InvalidToken,","class":"lineCov","hits":"1","order":"2473","possible_hits":"1",},
{"lineNum":"  363","line":"            \'.\' => .Dot,"},
{"lineNum":"  364","line":"            \'-\' => .Minus,"},
{"lineNum":"  365","line":"            \'(\' => .LParen,"},
{"lineNum":"  366","line":"            \')\' => .RParen,"},
{"lineNum":"  367","line":"            \'{\' => .LCurly,"},
{"lineNum":"  368","line":"            \'}\' => .RCurly,"},
{"lineNum":"  369","line":"            \'+\' => .Plus,"},
{"lineNum":"  370","line":"            \'*\' => .Mul,"},
{"lineNum":"  371","line":"            \'/\' => .Div,"},
{"lineNum":"  372","line":"            \';\' => .Semicolon,"},
{"lineNum":"  373","line":"            \',\' => .Comma,"},
{"lineNum":"  374","line":"            // TODO: improve error handling"},
{"lineNum":"  375","line":"            else => {"},
{"lineNum":"  376","line":"                if (lxr.file.len == 0) {","class":"lineCov","hits":"1","order":"3207","possible_hits":"1",},
{"lineNum":"  377","line":"                    log.err(\"error: unexpected character \\\'{c}\\\' in line=\\\"{s}\\\"@{any}:{any}\\n\", .{ lxr.ch, lxr.line.getSubStrFromStr(lxr.input), lxr.line_number, lxr.column });","class":"lineCov","hits":"1","order":"3208","possible_hits":"1",},
{"lineNum":"  378","line":"                } else {"},
{"lineNum":"  379","line":"                    log.err(\"error: unexpected character \\\'{c}\\\' in line=\\\"{s}\\\" in file=\\\"{s}\\\"@{any}:{any}\\n\", .{ lxr.ch, lxr.line.getSubStrFromStr(lxr.input), lxr.file, lxr.line_number, lxr.column });","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  380","line":"                }"},
{"lineNum":"  381","line":"                lxr.line.end = if (lxr.line.end == 0) @truncate(lxr.input.len) else lxr.line.end;","class":"lineCov","hits":"2","order":"3212","possible_hits":"2",},
{"lineNum":"  382","line":"                return error.InvalidToken;","class":"lineCov","hits":"2","order":"795","possible_hits":"2",},
{"lineNum":"  383","line":"            },"},
{"lineNum":"  384","line":"        };"},
{"lineNum":"  385","line":"        lxr.step();","class":"lineCov","hits":"1","order":"796","possible_hits":"1",},
{"lineNum":"  386","line":"        return tok;","class":"lineCov","hits":"1","order":"797","possible_hits":"1",},
{"lineNum":"  387","line":"    }"},
{"lineNum":"  388","line":""},
{"lineNum":"  389","line":"    fn slice(lxr: *Lexer, range: Range) []const u8 {","class":"lineCov","hits":"1","order":"736","possible_hits":"1",},
{"lineNum":"  390","line":"        const end = @min(range.end, lxr.input.len);","class":"lineCov","hits":"1","order":"737","possible_hits":"1",},
{"lineNum":"  391","line":"        return lxr.input[range.start..end];","class":"lineCov","hits":"1","order":"738","possible_hits":"1",},
{"lineNum":"  392","line":"    }"},
{"lineNum":"  393","line":"};"},
{"lineNum":"  394","line":""},
{"lineNum":"  395","line":"///////////"},
{"lineNum":"  396","line":"// TESTS //"},
{"lineNum":"  397","line":"///////////"},
{"lineNum":"  398","line":""},
{"lineNum":"  399","line":"const testAlloc = std.testing.allocator;"},
{"lineNum":"  400","line":""},
{"lineNum":"  401","line":"fn expect_token_kinds_equals(expected: []const TokenKind, actual: []Token) !void {","class":"lineCov","hits":"1","order":"3121","possible_hits":"1",},
{"lineNum":"  402","line":"    if (expected.len != actual.len) {","class":"lineCov","hits":"1","order":"3122","possible_hits":"1",},
{"lineNum":"  403","line":"        log.err(\"error: expected {d} tokens but got {d}\\n\", .{ expected.len, actual.len });","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  404","line":"        log.err(\"expected tokens:\\n{any}\\n\", .{expected});","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  405","line":"        log.err(\"got tokens:\\n{any}\\n\", .{actual});","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  406","line":"        return error.TokensDoNotMatch;","class":"linePartCov","hits":"1","order":"3123","possible_hits":"2",},
{"lineNum":"  407","line":"    }"},
{"lineNum":"  408","line":"    for (expected, 0..) |expected_kind, i| {","class":"lineCov","hits":"3","order":"3124","possible_hits":"3",},
{"lineNum":"  409","line":"        if (i >= actual.len) {","class":"lineCov","hits":"1","order":"3125","possible_hits":"1",},
{"lineNum":"  410","line":"            log.err(\"error: expected token kind {any} but got EOF\\n\", .{expected_kind});","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  411","line":"            return error.NotEnoughTokens;","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  412","line":"        }"},
{"lineNum":"  413","line":"        const actual_tok = actual[i];","class":"lineCov","hits":"3","order":"3126","possible_hits":"3",},
{"lineNum":"  414","line":"        const actual_kind = actual_tok.kind;","class":"lineCov","hits":"1","order":"3127","possible_hits":"1",},
{"lineNum":"  415","line":"        if (!expected_kind.equals(actual_kind)) {","class":"lineCov","hits":"1","order":"3128","possible_hits":"1",},
{"lineNum":"  416","line":"            log.err(\"error: expected token kind {any} but got {any}\\n\", .{ expected_kind, actual_kind });","class":"lineNoCov","hits":"0","possible_hits":"1",},
{"lineNum":"  417","line":"            return error.TokensDoNotMatch;","class":"linePartCov","hits":"4","order":"3129","possible_hits":"5",},
{"lineNum":"  418","line":"        }"},
{"lineNum":"  419","line":"    }"},
{"lineNum":"  420","line":"}"},
{"lineNum":"  421","line":""},
{"lineNum":"  422","line":"/// Check if the tokens produced by the lexer match the expected tokens."},
{"lineNum":"  423","line":"/// This function is useful for testing the lexer."},
{"lineNum":"  424","line":"///"},
{"lineNum":"  425","line":"/// @param contents:[]const u8        - The string to lex"},
{"lineNum":"  426","line":"/// @param expected:[]const TokenKind - The expected tokens"},
{"lineNum":"  427","line":"/// @return tokens:[]Token            - The tokens produced by the lexer"},
{"lineNum":"  428","line":"fn expect_results_in_tokens(contents: []const u8, expected: []const TokenKind) ![]Token {","class":"lineCov","hits":"1","order":"2930","possible_hits":"1",},
{"lineNum":"  429","line":"    const tokens = try Lexer.tokenizeFromStr(contents, testAlloc);","class":"lineCov","hits":"1","order":"2931","possible_hits":"1",},
{"lineNum":"  430","line":"    try expect_token_kinds_equals(expected, tokens);","class":"lineCov","hits":"1","order":"3120","possible_hits":"1",},
{"lineNum":"  431","line":"    return tokens;","class":"lineCov","hits":"1","order":"3130","possible_hits":"1",},
{"lineNum":"  432","line":"}"},
{"lineNum":"  433","line":""},
{"lineNum":"  434","line":"fn print_tokens(tokens: []Token) void {"},
{"lineNum":"  435","line":"    for (tokens) |token| {"},
{"lineNum":"  436","line":"        log.err(\"{}\\n\", .{token.kind});"},
{"lineNum":"  437","line":"    }"},
{"lineNum":"  438","line":"}"},
{"lineNum":"  439","line":""},
{"lineNum":"  440","line":"const expect = std.testing.expect;"},
{"lineNum":"  441","line":""},
{"lineNum":"  442","line":"test \"add\" {","class":"lineCov","hits":"1","order":"2928","possible_hits":"1",},
{"lineNum":"  443","line":"    const tokens = try expect_results_in_tokens(\"1+2\", &[_]TokenKind{","class":"lineCov","hits":"1","order":"2929","possible_hits":"1",},
{"lineNum":"  444","line":"        .Number,"},
{"lineNum":"  445","line":"        .Plus,"},
{"lineNum":"  446","line":"        .Number,"},
{"lineNum":"  447","line":"        .Eof,"},
{"lineNum":"  448","line":"    });"},
{"lineNum":"  449","line":"    defer testAlloc.free(tokens);","class":"lineCov","hits":"1","order":"3131","possible_hits":"1",},
{"lineNum":"  450","line":"}"},
{"lineNum":"  451","line":""},
{"lineNum":"  452","line":"test \"simple_struct\" {","class":"lineCov","hits":"1","order":"3190","possible_hits":"1",},
{"lineNum":"  453","line":"    const content = \"struct SimpleStruct { int x; int y; }\";","class":"lineCov","hits":"1","order":"3191","possible_hits":"1",},
{"lineNum":"  454","line":"    const tokens = try expect_results_in_tokens(content, &[_]TokenKind{","class":"lineCov","hits":"1","order":"3192","possible_hits":"1",},
{"lineNum":"  455","line":"        .KeywordStruct,"},
{"lineNum":"  456","line":"        .Identifier,"},
{"lineNum":"  457","line":"        .LCurly,"},
{"lineNum":"  458","line":"        .KeywordInt,"},
{"lineNum":"  459","line":"        .Identifier,"},
{"lineNum":"  460","line":"        .Semicolon,"},
{"lineNum":"  461","line":"        .KeywordInt,"},
{"lineNum":"  462","line":"        .Identifier,"},
{"lineNum":"  463","line":"        .Semicolon,"},
{"lineNum":"  464","line":"        .RCurly,"},
{"lineNum":"  465","line":"        .Eof,"},
{"lineNum":"  466","line":"    });"},
{"lineNum":"  467","line":"    defer testAlloc.free(tokens);","class":"linePartCov","hits":"1","order":"3197","possible_hits":"3",},
{"lineNum":"  468","line":"    const ident_token = tokens[1];","class":"lineCov","hits":"2","order":"3194","possible_hits":"2",},
{"lineNum":"  469","line":"    try expect(ident_token.kind == TokenKind.Identifier);","class":"linePartCov","hits":"1","order":"3195","possible_hits":"2",},
{"lineNum":"  470","line":""},
{"lineNum":"  471","line":"    // NODE: this should be implemented in some manner, I\'ve hacked it out to reduce mem size"},
{"lineNum":"  472","line":"    //if (ident_token._range) |range| {"},
{"lineNum":"  473","line":"    //    try expect(std.mem.eql(u8, range.getSubStrFromStr(content), \"SimpleStruct\"));"},
{"lineNum":"  474","line":"    //} else {"},
{"lineNum":"  475","line":"    //    log.err(\"error: expected range for identifier token but got none\\n\", .{});"},
{"lineNum":"  476","line":"    //    return error.NoRangeForToken;"},
{"lineNum":"  477","line":"    //}"},
{"lineNum":"  478","line":"    try expect(std.mem.eql(u8, ident_token._range.getSubStrFromStr(content), \"SimpleStruct\"));","class":"linePartCov","hits":"1","order":"3196","possible_hits":"2",},
{"lineNum":"  479","line":"}"},
{"lineNum":"  480","line":""},
{"lineNum":"  481","line":"// TODO add deallocation"},
{"lineNum":"  482","line":"test \"ident_can_not_start_with_num\" {","class":"lineCov","hits":"1","order":"3198","possible_hits":"1",},
{"lineNum":"  483","line":"    // NOTE: we should probably decide on how to handle this"},
{"lineNum":"  484","line":"    // OPTION A: do harder validation work in lexer for checking if"},
{"lineNum":"  485","line":"    //           thing after number is valid token (i.e. parsings job)"},
{"lineNum":"  486","line":"    //           and recognize it is invalid number"},
{"lineNum":"  487","line":"    // OPTION B: do easier validation in parser and don\'t identify it as"},
{"lineNum":"  488","line":"    //           invalid number, rather number,ident as invalid sequence"},
{"lineNum":"  489","line":"    //           THIS IS THE EASIEST AND THEREFORE BEST OPTION"},
{"lineNum":"  490","line":"    // OPTION C: do harder validation in parser, when identifying"},
{"lineNum":"  491","line":"    //           invalid sequence from (B), checking if it does not"},
{"lineNum":"  492","line":"    //           have whitespace before it and is therefore an invalid number"},
{"lineNum":"  493","line":"    //           not invalid sequence"},
{"lineNum":"  494","line":""},
{"lineNum":"  495","line":"    const tokens = try expect_results_in_tokens(\"1foo\", &[_]TokenKind{","class":"lineCov","hits":"1","order":"3199","possible_hits":"1",},
{"lineNum":"  496","line":"        .Number,"},
{"lineNum":"  497","line":"        .Identifier,"},
{"lineNum":"  498","line":"        .Eof,"},
{"lineNum":"  499","line":"    });"},
{"lineNum":"  500","line":"    defer testAlloc.free(tokens);","class":"lineCov","hits":"1","order":"3200","possible_hits":"1",},
{"lineNum":"  501","line":"}"},
{"lineNum":"  502","line":""},
{"lineNum":"  503","line":"test \"all_binops\" {","class":"lineCov","hits":"1","order":"3201","possible_hits":"1",},
{"lineNum":"  504","line":"    const tokens = try expect_results_in_tokens(\"+ - * / <= >= = ==\", &[_]TokenKind{","class":"lineCov","hits":"1","order":"3202","possible_hits":"1",},
{"lineNum":"  505","line":"        .Plus,"},
{"lineNum":"  506","line":"        .Minus,"},
{"lineNum":"  507","line":"        .Mul,"},
{"lineNum":"  508","line":"        .Div,"},
{"lineNum":"  509","line":"        .LtEq,"},
{"lineNum":"  510","line":"        .GtEq,"},
{"lineNum":"  511","line":"        .Eq,"},
{"lineNum":"  512","line":"        .DoubleEq,"},
{"lineNum":"  513","line":"        .Eof,"},
{"lineNum":"  514","line":"    });"},
{"lineNum":"  515","line":"    defer testAlloc.free(tokens);","class":"lineCov","hits":"1","order":"3203","possible_hits":"1",},
{"lineNum":"  516","line":"}"},
{"lineNum":"  517","line":""},
{"lineNum":"  518","line":"test \"invalid_char\" {","class":"lineCov","hits":"1","order":"3204","possible_hits":"1",},
{"lineNum":"  519","line":"    const contents = \"%foo;\";","class":"lineCov","hits":"1","order":"3205","possible_hits":"1",},
{"lineNum":"  520","line":"    try std.testing.expectError(error.InvalidToken, Lexer.tokenizeFromStr(contents, testAlloc));","class":"lineCov","hits":"1","order":"3206","possible_hits":"1",},
{"lineNum":"  521","line":"}"},
{"lineNum":"  522","line":""},
{"lineNum":"  523","line":"test \"invalid_char_in_ident\" {","class":"lineCov","hits":"1","order":"3213","possible_hits":"1",},
{"lineNum":"  524","line":"    const contents = \"foo%bar\";","class":"lineCov","hits":"1","order":"3214","possible_hits":"1",},
{"lineNum":"  525","line":"    try std.testing.expectError(error.InvalidToken, Lexer.tokenizeFromStr(contents, testAlloc));","class":"lineCov","hits":"1","order":"3215","possible_hits":"1",},
{"lineNum":"  526","line":"}"},
{"lineNum":"  527","line":""},
{"lineNum":"  528","line":"// TODO: update this"},
{"lineNum":"  529","line":"test \"all_keywords\" {","class":"lineCov","hits":"1","order":"3216","possible_hits":"1",},
{"lineNum":"  530","line":"    const tokens = try expect_results_in_tokens(\"delete endl false fun if new null read return struct true while\", &[_]TokenKind{","class":"lineCov","hits":"1","order":"3217","possible_hits":"1",},
{"lineNum":"  531","line":"        .KeywordDelete,"},
{"lineNum":"  532","line":"        .KeywordEndl,"},
{"lineNum":"  533","line":"        .KeywordFalse,"},
{"lineNum":"  534","line":"        .KeywordFun,"},
{"lineNum":"  535","line":"        .KeywordIf,"},
{"lineNum":"  536","line":"        .KeywordNew,"},
{"lineNum":"  537","line":"        .KeywordNull,"},
{"lineNum":"  538","line":"        .KeywordRead,"},
{"lineNum":"  539","line":"        .KeywordReturn,"},
{"lineNum":"  540","line":"        .KeywordStruct,"},
{"lineNum":"  541","line":"        .KeywordTrue,"},
{"lineNum":"  542","line":"        .KeywordWhile,"},
{"lineNum":"  543","line":"        .Eof,"},
{"lineNum":"  544","line":"    });"},
{"lineNum":"  545","line":"    defer testAlloc.free(tokens);","class":"lineCov","hits":"1","order":"3218","possible_hits":"1",},
{"lineNum":"  546","line":"}"},
{"lineNum":"  547","line":""},
{"lineNum":"  548","line":"test \"ident_with_num\" {","class":"lineCov","hits":"1","order":"3219","possible_hits":"1",},
{"lineNum":"  549","line":"    const tokens = try expect_results_in_tokens(\"foo1\", &[_]TokenKind{","class":"lineCov","hits":"1","order":"3220","possible_hits":"1",},
{"lineNum":"  550","line":"        .Identifier,"},
{"lineNum":"  551","line":"        .Eof,"},
{"lineNum":"  552","line":"    });"},
{"lineNum":"  553","line":"    defer testAlloc.free(tokens);","class":"lineCov","hits":"1","order":"3221","possible_hits":"1",},
{"lineNum":"  554","line":"}"},
]};
var percent_low = 25;var percent_high = 75;
var header = { "command" : "test", "date" : "2024-04-26 16:14:49", "instrumented" : 177, "covered" : 165,};
var merged_data = [];
